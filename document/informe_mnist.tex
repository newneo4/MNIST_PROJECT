\documentclass[12pt,a4paper]{article}

% ==================== PAQUETES ====================
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{array}
\usepackage{longtable}
\usepackage{enumitem}

\geometry{margin=2.5cm}

% Configuración de listings para código R
\lstset{
    language=R,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray}
}

% ==================== ENCABEZADO ====================
\pagestyle{fancy}
\fancyhf{}
\rhead{Reconocimiento de Dígitos con CNN}
\lhead{MNIST en R}
\cfoot{\thepage}

% ==================== TÍTULO ====================
\title{
    \vspace{-2cm}
    \textbf{Reconocimiento de Dígitos Manuscritos con Redes Neuronales Convolucionales (CNN)}\\[0.5cm]
    \large Implementación en R utilizando la Metodología Fundacional de IBM para Ciencia de Datos
}
\author{
    \textbf{Autor}\\
    Universidad / Institución\\
    \texttt{correo@ejemplo.com}
}
\date{Diciembre 2025}

\begin{document}

\maketitle

% ==================== RESUMEN ====================
\begin{abstract}
\noindent
\textbf{Resumen:} El presente trabajo aborda el desarrollo de un modelo de aprendizaje profundo para la clasificación automática de dígitos manuscritos (0-9) utilizando Redes Neuronales Convolucionales (CNN) implementadas en el lenguaje de programación R. Se empleó el conjunto de datos MNIST, ampliamente reconocido como referencia en tareas de visión por computadora. La metodología de trabajo se estructuró siguiendo la \textbf{Metodología Fundacional de IBM para Ciencia de Datos}, que comprende ocho fases iterativas: enfoque analítico, requerimientos de datos, recolección, comprensión, preparación, modelado, evaluación y despliegue. El modelo desarrollado alcanzó una exactitud del \textbf{99.27\%} en el conjunto de prueba, con una pérdida de 0.0206, demostrando la eficacia de las CNN para tareas de reconocimiento de patrones visuales. El análisis de la matriz de confusión reveló que los errores de clasificación se concentran principalmente entre dígitos con similitudes morfológicas, como el 3 y el 5 o el 4 y el 9.

\vspace{0.3cm}
\noindent
\textbf{Abstract:} This work addresses the development of a deep learning model for the automatic classification of handwritten digits (0-9) using Convolutional Neural Networks (CNN) implemented in the R programming language. The MNIST dataset was used, widely recognized as a benchmark in computer vision tasks. The working methodology was structured following the \textbf{IBM Foundational Methodology for Data Science}, comprising eight iterative phases: analytical approach, data requirements, collection, understanding, preparation, modeling, evaluation, and deployment. The developed model achieved an accuracy of \textbf{99.27\%} on the test set, with a loss of 0.0206, demonstrating the effectiveness of CNNs for visual pattern recognition tasks. Analysis of the confusion matrix revealed that classification errors are primarily concentrated among digits with morphological similarities.

\vspace{0.3cm}
\noindent
\textbf{Dataset utilizado:} MNIST (Modified National Institute of Standards and Technology)

\vspace{0.2cm}
\noindent
\textbf{Metodología aplicada:} Metodología Fundacional de IBM para Ciencia de Datos

\vspace{0.2cm}
\noindent
\textbf{Resultados principales:} Exactitud del 99.27\% en clasificación de 10 clases

\vspace{0.3cm}
\noindent
\textbf{Palabras clave:} Redes Neuronales Convolucionales, MNIST, Aprendizaje Profundo, Clasificación de Imágenes, R, Keras, TensorFlow, Visión por Computadora

\vspace{0.2cm}
\noindent
\textbf{Keywords:} Convolutional Neural Networks, MNIST, Deep Learning, Image Classification, R, Keras, TensorFlow, Computer Vision
\end{abstract}

\newpage
\tableofcontents
\newpage

% ==================== INTRODUCCIÓN ====================
\section{Introducción}

\subsection{Contexto del Problema}
El reconocimiento automático de caracteres manuscritos representa uno de los desafíos fundamentales en el campo de la visión por computadora y el aprendizaje automático. Desde los primeros intentos en la década de 1950, cuando Frank Rosenblatt desarrolló el perceptrón, hasta las sofisticadas arquitecturas de aprendizaje profundo actuales, la capacidad de las máquinas para interpretar correctamente la escritura humana ha sido un objetivo central de la investigación en inteligencia artificial.

La escritura manuscrita presenta desafíos únicos debido a su naturaleza inherentemente variable. A diferencia del texto impreso, donde cada carácter tiene una forma predefinida y consistente, la escritura a mano refleja las características individuales de cada persona: el grosor del trazo, la inclinación, las proporciones relativas y los estilos cursivos o de imprenta varían significativamente entre individuos e incluso en diferentes momentos para una misma persona.

Las aplicaciones prácticas de esta tecnología son extensas y de alto impacto:
\begin{itemize}[nosep]
    \item \textbf{Sector financiero:} Procesamiento automático de cheques y formularios bancarios
    \item \textbf{Servicios postales:} Lectura de códigos postales y direcciones
    \item \textbf{Digitalización documental:} Conversión de archivos históricos a formato digital
    \item \textbf{Accesibilidad:} Asistencia para personas con discapacidades visuales
    \item \textbf{Educación:} Calificación automatizada de exámenes
\end{itemize}

\subsection{Importancia del Estudio}
Las Redes Neuronales Convolucionales (CNN, por sus siglas en inglés \textit{Convolutional Neural Networks}) han revolucionado el campo del procesamiento de imágenes desde la publicación del trabajo seminal de LeCun et al. en 1998, donde se introdujo la arquitectura LeNet-5 específicamente para el reconocimiento de dígitos.

A diferencia de los métodos tradicionales de visión por computadora que dependían de la ingeniería manual de características (como histogramas de gradientes orientados o filtros Gabor), las CNN poseen la capacidad de \textbf{aprender automáticamente} las representaciones más relevantes para la tarea en cuestión. Esta propiedad, conocida como \textit{aprendizaje de representaciones}, permite que la red descubra patrones desde los más básicos (bordes, texturas) hasta los más complejos (formas, objetos) de manera jerárquica.

El conjunto de datos MNIST ha servido como piedra angular para la evaluación de algoritmos de clasificación de imágenes durante más de dos décadas. Con sus 70,000 imágenes de dígitos manuscritos, proporciona un problema lo suficientemente complejo para ser interesante, pero lo suficientemente manejable para permitir experimentación rápida —una combinación que lo ha convertido en el ``Hello World'' del aprendizaje profundo.

\subsection{Motivación del Trabajo}
Este trabajo se desarrolló con múltiples objetivos pedagógicos y prácticos:

\begin{enumerate}
    \item \textbf{Demostrar la viabilidad de R para Deep Learning:} Aunque Python domina el ecosistema de aprendizaje profundo, R ofrece capacidades equivalentes a través de la integración con Keras y TensorFlow, manteniendo las fortalezas de R en análisis estadístico y visualización.
    
    \item \textbf{Aplicar una metodología estructurada:} La Metodología Fundacional de IBM proporciona un marco iterativo y reproducible que distingue proyectos profesionales de ciencia de datos de aproximaciones ad-hoc.
    
    \item \textbf{Comprender los fundamentos de las CNN:} Más allá de obtener un modelo funcional, este estudio busca desarrollar una comprensión profunda de cómo las capas convolucionales extraen características y cómo el entrenamiento ajusta los parámetros.
\end{enumerate}

% ==================== MARCO TEÓRICO ====================
\section{Marco Teórico}

\subsection{Fundamentos del Aprendizaje Profundo}

El aprendizaje profundo (\textit{Deep Learning}) es una subrama del aprendizaje automático que utiliza redes neuronales artificiales con múltiples capas para aprender representaciones jerárquicas de los datos. El término ``profundo'' hace referencia al número de capas ocultas en la arquitectura, que puede variar desde unas pocas hasta cientos en modelos modernos.

\subsubsection{La Neurona Artificial}
La unidad básica de una red neuronal es la neurona artificial, modelada de forma simplificada a partir de las neuronas biológicas. Matemáticamente, una neurona computa:

\begin{equation}
    y = \sigma\left(\sum_{i=1}^{n} w_i x_i + b\right) = \sigma(\mathbf{w}^T\mathbf{x} + b)
\end{equation}

donde:
\begin{itemize}[nosep]
    \item $\mathbf{x} = (x_1, x_2, ..., x_n)$ son las entradas
    \item $\mathbf{w} = (w_1, w_2, ..., w_n)$ son los pesos sinápticos (parámetros aprendibles)
    \item $b$ es el sesgo (\textit{bias})
    \item $\sigma$ es la función de activación
\end{itemize}

\subsubsection{Funciones de Activación}
Las funciones de activación introducen no linealidad en la red, permitiendo que aprenda relaciones complejas. En este trabajo utilizamos:

\textbf{ReLU (Rectified Linear Unit):}
\begin{equation}
    \text{ReLU}(x) = \max(0, x)
\end{equation}

ReLU se ha convertido en la función de activación estándar para capas ocultas debido a su simplicidad computacional y su capacidad para mitigar el problema del desvanecimiento del gradiente (\textit{vanishing gradient}).

\textbf{Softmax:}
\begin{equation}
    \text{Softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
\end{equation}

Softmax se utiliza en la capa de salida para problemas de clasificación multiclase, ya que convierte un vector de valores reales en una distribución de probabilidad sobre las $K$ clases.

\subsection{Redes Neuronales Convolucionales}

Las CNN son una clase especializada de redes neuronales diseñadas específicamente para procesar datos con estructura de cuadrícula, como imágenes (cuadrícula 2D de píxeles) o señales de audio (cuadrícula 1D).

\subsubsection{La Operación de Convolución}
La convolución discreta en 2D se define como:

\begin{equation}
    (I * K)(i, j) = \sum_{m}\sum_{n} I(i-m, j-n) \cdot K(m, n)
\end{equation}

donde $I$ es la imagen de entrada y $K$ es el kernel o filtro convolucional. Esta operación desliza el kernel sobre la imagen, computando en cada posición el producto punto entre el kernel y la región correspondiente de la imagen.

\textbf{Ventajas de la convolución:}
\begin{itemize}
    \item \textbf{Conectividad dispersa:} Cada neurona se conecta solo a una región local de la entrada, reduciendo drásticamente el número de parámetros.
    \item \textbf{Compartición de pesos:} El mismo kernel se aplica en todas las posiciones espaciales, lo que permite detectar el mismo patrón independientemente de su ubicación (equivarianza a traslación).
    \item \textbf{Jerarquía de características:} Capas sucesivas aprenden características progresivamente más abstractas.
\end{itemize}

\subsubsection{Capas de Pooling}
Las capas de pooling (submuestreo) reducen la dimensionalidad espacial de las representaciones, controlando el sobreajuste y reduciendo la carga computacional. El \textbf{Max Pooling} selecciona el valor máximo en cada ventana:

\begin{equation}
    y_{i,j} = \max_{(m,n) \in R_{i,j}} x_{m,n}
\end{equation}

donde $R_{i,j}$ es la región de pooling correspondiente a la posición $(i,j)$ de salida.

\subsubsection{Regularización: Dropout}
Dropout es una técnica de regularización que previene el sobreajuste al ``apagar'' aleatoriamente una fracción $p$ de las neuronas durante el entrenamiento. Matemáticamente:

\begin{equation}
    \tilde{h}_i = r_i \cdot h_i, \quad r_i \sim \text{Bernoulli}(1-p)
\end{equation}

Durante la inferencia, todas las neuronas permanecen activas pero sus salidas se escalan por $(1-p)$ para compensar.

\subsection{Entrenamiento de Redes Neuronales}

\subsubsection{Función de Pérdida: Entropía Cruzada Categórica}
Para clasificación multiclase con codificación one-hot, la función de pérdida estándar es:

\begin{equation}
    \mathcal{L}(\mathbf{y}, \hat{\mathbf{y}}) = -\sum_{i=1}^{K} y_i \log(\hat{y}_i)
\end{equation}

donde $\mathbf{y}$ es el vector one-hot de la clase verdadera y $\hat{\mathbf{y}}$ es la distribución de probabilidad predicha por softmax.

\subsubsection{Optimizador Adam}
Adam (Adaptive Moment Estimation) combina las ventajas de dos extensiones de SGD: AdaGrad y RMSProp. Mantiene estimaciones de primer y segundo momento de los gradientes:

\begin{align}
    m_t &= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
    v_t &= \beta_2 v_{t-1} + (1-\beta_2) g_t^2 \\
    \theta_t &= \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\end{align}

donde $\hat{m}_t$ y $\hat{v}_t$ son versiones corregidas por sesgo de $m_t$ y $v_t$.

\subsection{Metodología Fundacional de IBM para Ciencia de Datos}

Esta metodología proporciona un marco estructurado para proyectos de ciencia de datos, desarrollado por IBM basándose en décadas de experiencia práctica. A diferencia de CRISP-DM, que tiene un enfoque más orientado a minería de datos, la metodología IBM enfatiza aspectos específicos de la ciencia de datos moderna.

\begin{figure}[H]
\centering
\begin{tabular}{|c|l|p{7cm}|}
\hline
\textbf{Fase} & \textbf{Nombre} & \textbf{Descripción} \\
\hline
1 & Enfoque Analítico & Determinar el tipo de problema y técnica apropiada \\
2 & Requerimientos de Datos & Identificar datos necesarios \\
3 & Recolección de Datos & Obtener los datos requeridos \\
4 & Comprensión de Datos & Explorar y entender los datos \\
5 & Preparación de Datos & Limpiar y transformar los datos \\
6 & Modelado & Construir modelos predictivos o descriptivos \\
7 & Evaluación & Valorar la calidad del modelo \\
8 & Despliegue & Implementar el modelo en producción \\
\hline
\end{tabular}
\caption{Fases de la Metodología Fundacional de IBM}
\end{figure}

\subsection{Visualización de la Arquitectura CNN}

La Figura \ref{fig:arquitectura} presenta un diagrama esquemático del flujo de datos a través de las capas de la red neuronal convolucional utilizada en este estudio.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{img_arquitectura.png}
    \caption{Diagrama de la arquitectura CNN. Se observa el flujo secuencial desde la entrada (28×28×1) a través de bloques convolucionales con pooling, seguidos de aplanamiento y capas densas hasta la salida de 10 clases. Cada color representa un tipo de capa diferente: azul para convolución, verde para pooling, naranja para flatten, morado para dense y rojo para dropout.}
    \label{fig:arquitectura}
\end{figure}

% ==================== PLANTEAMIENTO DEL PROBLEMA ====================
\section{Planteamiento del Problema}

El problema central de este estudio se define como una tarea de \textbf{clasificación multiclase supervisada}, donde el objetivo es asignar correctamente cada imagen de un dígito manuscrito a una de las diez categorías posibles (dígitos del 0 al 9).

\subsection{Formalización Matemática}
Dado:
\begin{itemize}
    \item Un conjunto de entrenamiento $\mathcal{D}_{train} = \{(\mathbf{x}^{(i)}, y^{(i)})\}_{i=1}^{N}$ donde $\mathbf{x}^{(i)} \in \mathbb{R}^{28 \times 28}$ y $y^{(i)} \in \{0, 1, ..., 9\}$
    \item Un conjunto de prueba $\mathcal{D}_{test}$ con la misma estructura
\end{itemize}

El objetivo es aprender una función $f_\theta: \mathbb{R}^{28 \times 28} \rightarrow \{0, 1, ..., 9\}$ parametrizada por $\theta$ que minimice el error de clasificación esperado:

\begin{equation}
    \theta^* = \arg\min_\theta \mathbb{E}_{(\mathbf{x}, y) \sim \mathcal{D}}\left[\mathbf{1}_{f_\theta(\mathbf{x}) \neq y}\right]
\end{equation}

En la práctica, optimizamos un proxy diferenciable (la pérdida de entropía cruzada) usando descenso de gradiente estocástico.

\subsection{Preguntas de Investigación}
\begin{enumerate}
    \item ¿Es posible alcanzar una exactitud superior al 99\% en la clasificación de dígitos MNIST utilizando una arquitectura CNN de complejidad moderada?
    \item ¿Cuáles son los patrones de confusión más frecuentes entre dígitos y qué características morfológicas los explican?
    \item ¿Cómo evoluciona el proceso de aprendizaje a través de las épocas, y qué indicadores permiten detectar sobreajuste?
    \item ¿Es viable implementar un pipeline completo de aprendizaje profundo utilizando exclusivamente el ecosistema R?
\end{enumerate}

% ==================== OBJETIVOS ====================
\section{Objetivos}

\subsection{Objetivo General}
Desarrollar e implementar un modelo de Red Neuronal Convolucional en R para la clasificación automática de dígitos manuscritos del conjunto de datos MNIST, siguiendo la Metodología Fundacional de IBM para Ciencia de Datos, alcanzando una exactitud superior al 98\% en el conjunto de prueba.

\subsection{Objetivos Específicos}
\begin{enumerate}
    \item Realizar un análisis exploratorio exhaustivo del conjunto de datos MNIST para verificar su estructura, distribución de clases y características visuales.
    
    \item Diseñar e implementar funciones personalizadas en R para la lectura del formato binario IDX propietario del dataset.
    
    \item Aplicar técnicas de preprocesamiento apropiadas: normalización de píxeles, reestructuración dimensional para compatibilidad con Keras, y codificación one-hot de etiquetas.
    
    \item Construir una arquitectura CNN que incluya capas convolucionales, pooling, dropout y densas, justificando cada decisión de diseño.
    
    \item Entrenar el modelo monitoreando métricas de entrenamiento y validación para detectar posible sobreajuste.
    
    \item Evaluar cuantitativamente el rendimiento mediante exactitud, pérdida y análisis detallado de la matriz de confusión.
    
    \item Documentar el proceso completo de acuerdo con las fases de la Metodología Fundacional de IBM.
\end{enumerate}

% ==================== DESCRIPCIÓN DEL DATASET ====================
\section{Descripción del Dataset}

\subsection{Origen Histórico}
El conjunto de datos MNIST (Modified National Institute of Standards and Technology) fue creado en 1998 por Yann LeCun, Corinna Cortes y Christopher J.C. Burges. Se derivó de dos bases de datos originales del NIST:
\begin{itemize}
    \item \textbf{Special Database 1 (SD-1):} Dígitos escritos por estudiantes de secundaria
    \item \textbf{Special Database 3 (SD-3):} Dígitos escritos por empleados del Census Bureau
\end{itemize}

Las modificaciones incluyeron normalización del tamaño, centrado en una cuadrícula de $28 \times 28$ píxeles, y aplicación de filtros de antialiasing para suavizar los bordes.

\subsection{Composición Cuantitativa}
\begin{table}[H]
\centering
\caption{Composición del conjunto de datos MNIST}
\begin{tabular}{lccc}
\toprule
\textbf{Conjunto} & \textbf{Imágenes} & \textbf{Proporción} & \textbf{Origen NIST} \\
\midrule
Entrenamiento & 60,000 & 85.7\% & Mezclado SD-1 y SD-3 \\
Prueba & 10,000 & 14.3\% & Mezclado SD-1 y SD-3 \\
\midrule
\textbf{Total} & \textbf{70,000} & \textbf{100\%} & --- \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Especificaciones Técnicas}
\begin{table}[H]
\centering
\caption{Características técnicas de las imágenes MNIST}
\begin{tabular}{ll}
\toprule
\textbf{Característica} & \textbf{Valor} \\
\midrule
Dimensiones espaciales & $28 \times 28$ píxeles \\
Canales de color & 1 (escala de grises) \\
Profundidad de bits & 8 bits (0-255) \\
Formato de almacenamiento & IDX (binario, big-endian) \\
Tamaño por imagen & 784 bytes (sin comprimir) \\
Clases & 10 (dígitos 0-9) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Visualización de Muestras Representativas}
La Figura \ref{fig:muestras} presenta 12 ejemplos del conjunto de entrenamiento, ilustrando la variabilidad estilística inherente a la escritura manuscrita. Se observan diferencias significativas en:

\begin{itemize}
    \item \textbf{Grosor del trazo:} Desde líneas finas hasta trazos gruesos
    \item \textbf{Inclinación:} Variación en el ángulo de escritura
    \item \textbf{Proporciones:} Diferencias en altura y anchura relativas
    \item \textbf{Estilo:} Formas cursivas versus de imprenta
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img_muestras.png}
    \caption{Muestras representativas del conjunto de datos MNIST. Cada imagen muestra un dígito manuscrito con su etiqueta correspondiente. Nótese la diversidad de estilos de escritura: el ``5'' superior izquierdo tiene un trazo grueso y angular, mientras que el ``1'' superior derecho es delgado e inclinado. Esta variabilidad constituye el desafío central que el modelo debe aprender a manejar.}
    \label{fig:muestras}
\end{figure}

% ==================== METODOLOGÍA ====================
\section{Metodología}

Este estudio se estructuró rigurosamente siguiendo la \textbf{Metodología Fundacional de IBM para Ciencia de Datos}, adaptando cada fase al contexto específico del problema de clasificación de dígitos.

\subsection{Fase 1: Enfoque Analítico}
Se identificó el problema como \textbf{clasificación supervisada multiclase}, descartando alternativas como:
\begin{itemize}
    \item Regresión: Inapropiada porque las etiquetas son categóricas, no continuas
    \item Clustering: Inapropiado porque disponemos de etiquetas (aprendizaje supervisado)
    \item Detección de anomalías: No aplica al contexto del problema
\end{itemize}

La técnica seleccionada fueron las \textbf{Redes Neuronales Convolucionales} debido a:
\begin{enumerate}
    \item Capacidad demostrada en tareas de visión por computadora
    \item Aprendizaje automático de características jerárquicas
    \item Estado del arte en benchmarks de clasificación de imágenes
    \item Disponibilidad de implementaciones maduras en R/Keras
\end{enumerate}

\subsection{Fase 2: Requerimientos de Datos}
Se identificaron los siguientes requisitos:
\begin{itemize}
    \item Imágenes de dígitos manuscritos normalizadas en tamaño
    \item Etiquetas categóricas verificadas (ground truth)
    \item Separación predefinida entre entrenamiento y prueba
    \item Cantidad suficiente para entrenamiento de deep learning (miles de ejemplos por clase)
\end{itemize}

El dataset MNIST satisface todos estos requisitos de manera óptima.

\subsection{Fase 3: Recolección de Datos}
Los datos se obtuvieron del repositorio de Kaggle en formato IDX binario. Se implementaron funciones personalizadas en R para parsear este formato, ya que no existe una biblioteca estándar en R para lectura de archivos IDX.

\subsection{Fases 4-8: Ejecución}
Las fases restantes (comprensión, preparación, modelado, evaluación y despliegue) se documentan en detalle en las secciones de Resultados y Evaluación.

\subsection{Herramientas y Entorno Técnico}
\begin{table}[H]
\centering
\caption{Stack tecnológico utilizado}
\begin{tabular}{lll}
\toprule
\textbf{Componente} & \textbf{Tecnología} & \textbf{Propósito} \\
\midrule
Lenguaje & R 4.x & Programación principal \\
Deep Learning & Keras 2.x + TensorFlow 2.x & Construcción y entrenamiento de CNN \\
Visualización & ggplot2, graphics & Gráficos estadísticos \\
Manipulación & tidyverse & Transformación de datos \\
Entorno & Kaggle Notebooks & Ejecución reproducible \\
\bottomrule
\end{tabular}
\end{table}

% ==================== RESULTADOS ====================
\section{Resultados}

\subsection{Limpieza y Procesamiento de Datos}

\subsubsection{Lectura del Formato IDX}
El formato IDX utiliza codificación big-endian con una estructura de cabecera específica:
\begin{itemize}
    \item Bytes 0-3: Magic number (identifica tipo de datos)
    \item Bytes 4-7: Número de elementos
    \item Bytes 8-11: Número de filas (solo imágenes)
    \item Bytes 12-15: Número de columnas (solo imágenes)
    \item Resto: Datos en formato unsigned byte
\end{itemize}

Se implementaron funciones \texttt{read\_idx\_images()} y \texttt{read\_idx\_labels()} que utilizan \texttt{readBin()} con el parámetro \texttt{endian="big"} para la correcta interpretación de los enteros de la cabecera.

\subsubsection{Pipeline de Preprocesamiento}
El preprocesamiento siguió una secuencia de cuatro transformaciones críticas:

\begin{enumerate}
    \item \textbf{Reestructuración dimensional:} R almacena arrays en orden \textit{column-major}, mientras que IDX utiliza orden \textit{row-major}. Se aplicó \texttt{aperm()} para permutar las dimensiones correctamente, transformando de $(cols, rows, n)$ a $(n, rows, cols)$.
    
    \item \textbf{Adición del canal:} Keras espera tensores 4D de forma $(batch, height, width, channels)$. Se expandió la dimensión del canal usando \texttt{array\_reshape()}, resultando en $(n, 28, 28, 1)$.
    
    \item \textbf{Normalización:} Se dividieron los valores de píxeles por 255 para escalar al rango $[0, 1]$:
    \begin{equation}
        x_{norm} = \frac{x_{raw}}{255}
    \end{equation}
    Esta normalización acelera la convergencia del optimizador al mantener los gradientes en rangos manejables.
    
    \item \textbf{Codificación One-Hot:} Las etiquetas enteras se transformaron en vectores binarios de longitud 10. Por ejemplo, la etiqueta $3$ se convierte en:
    \begin{equation}
        \mathbf{y} = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
    \end{equation}
\end{enumerate}

\begin{table}[H]
\centering
\caption{Dimensiones de los datos en cada etapa del preprocesamiento}
\begin{tabular}{lcc}
\toprule
\textbf{Etapa} & \textbf{Imágenes} & \textbf{Etiquetas} \\
\midrule
Original (IDX) & 60,000 $\times$ 28 $\times$ 28 & 60,000 (enteros) \\
Reestructurado & 60,000 $\times$ 28 $\times$ 28 $\times$ 1 & 60,000 (enteros) \\
Normalizado & 60,000 $\times$ 28 $\times$ 28 $\times$ 1 & 60,000 (enteros) \\
Final & 60,000 $\times$ 28 $\times$ 28 $\times$ 1 & 60,000 $\times$ 10 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Análisis Exploratorio de Datos (EDA)}

\subsubsection{Balance de Clases}
Un aspecto crítico en clasificación multiclase es verificar el balance de clases. La Figura \ref{fig:distribucion} presenta la distribución de frecuencias de cada dígito en el conjunto de entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img_distribucion.png}
    \caption{Distribución de clases en el conjunto de entrenamiento MNIST. El eje X representa cada dígito (0-9) y el eje Y el conteo de muestras. Se observa que el dígito ``1'' es el más frecuente (~6,700 muestras) mientras que el ``5'' es el menos representado (~5,400 muestras). Sin embargo, esta variación del ~20\% no constituye un desbalance severo que requiera técnicas de remuestreo.}
    \label{fig:distribucion}
\end{figure}

\textbf{Interpretación:} El dataset presenta un balance razonable. La proporción entre la clase más frecuente (1) y la menos frecuente (5) es aproximadamente 1.24:1, lo cual está dentro de rangos aceptables que no requieren técnicas de balanceo como SMOTE o submuestreo.

\subsection{Diseño y Arquitectura del Modelo}

\subsubsection{Justificación de la Arquitectura}
La arquitectura CNN diseñada sigue el patrón clásico establecido por LeNet-5, con adaptaciones modernas:

\begin{table}[H]
\centering
\caption{Arquitectura detallada del modelo CNN con justificación de diseño}
\begin{tabular}{llccp{4.5cm}}
\toprule
\textbf{\#} & \textbf{Capa} & \textbf{Salida} & \textbf{Params} & \textbf{Justificación} \\
\midrule
1 & Conv2D(32, 3×3, ReLU) & 26×26×32 & 320 & Detectar bordes y texturas básicas \\
2 & MaxPool2D(2×2) & 13×13×32 & 0 & Reducir dimensionalidad, invarianza a traslación \\
3 & Conv2D(64, 3×3, ReLU) & 11×11×64 & 18,496 & Combinar características de bajo nivel \\
4 & MaxPool2D(2×2) & 5×5×64 & 0 & Mayor abstracción espacial \\
5 & Flatten & 1,600 & 0 & Vectorizar para capas densas \\
6 & Dense(128, ReLU) & 128 & 204,928 & Aprender combinaciones no lineales \\
7 & Dropout(0.5) & 128 & 0 & Regularización contra sobreajuste \\
8 & Dense(10, Softmax) & 10 & 1,290 & Distribución de probabilidad final \\
\midrule
\multicolumn{3}{l}{\textbf{Total parámetros}} & \textbf{225,034} & \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Visualización de Filtros Aprendidos}
La Figura \ref{fig:filtros} muestra los 16 filtros de la primera capa convolucional después del entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{img_filtros.png}
    \caption{Filtros convolucionales (3×3) de la primera capa. Cada cuadro representa un filtro aprendido. Se observan patrones de detección de bordes en diferentes orientaciones: algunos filtros detectan bordes horizontales, otros verticales, y algunos diagonales. Estos constituyen los bloques básicos que la red utiliza para construir representaciones más complejas en capas posteriores.}
    \label{fig:filtros}
\end{figure}

\subsubsection{Mapas de Activación}
La Figura \ref{fig:activaciones} ilustra cómo una imagen de entrada se transforma al pasar por la primera capa convolucional.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{img_activaciones.png}
    \caption{Mapas de activación de la primera capa Conv2D para una imagen de muestra. Cada mapa representa la respuesta de un filtro diferente. Las regiones brillantes indican alta activación (el filtro detectó el patrón que busca). Se puede observar cómo diferentes filtros resaltan distintas características: algunos enfatizan los bordes del dígito, otros las curvas, y algunos el fondo.}
    \label{fig:activaciones}
\end{figure}

\subsubsection{Cálculo de Parámetros}
Para la primera capa convolucional:
\begin{equation}
    \text{Params} = (\text{kernel\_height} \times \text{kernel\_width} \times \text{input\_channels} + 1) \times \text{filters}
\end{equation}
\begin{equation}
    \text{Params} = (3 \times 3 \times 1 + 1) \times 32 = 320
\end{equation}

Para la capa densa de 128 unidades:
\begin{equation}
    \text{Params} = (\text{input\_size} + 1) \times \text{units} = (1600 + 1) \times 128 = 204,928
\end{equation}

\subsubsection{Configuración del Entrenamiento}
\begin{table}[H]
\centering
\caption{Hiperparámetros de entrenamiento}
\begin{tabular}{llp{6cm}}
\toprule
\textbf{Parámetro} & \textbf{Valor} & \textbf{Justificación} \\
\midrule
Optimizador & Adam & Convergencia rápida y estable, adaptativo \\
Learning rate & 0.001 & Valor por defecto de Adam, generalmente efectivo \\
Pérdida & Categorical CE & Estándar para clasificación multiclase \\
Épocas & 10 & Suficiente para convergencia en MNIST \\
Batch size & 128 & Balance entre velocidad y estabilidad del gradiente \\
Validación & 10\% & Monitorear generalización sin reducir mucho training \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Proceso de Entrenamiento}

\subsubsection{Análisis de Curvas de Aprendizaje}
La Figura \ref{fig:entrenamiento} muestra la evolución de las métricas durante las 10 épocas de entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{img_entrenamiento.png}
    \caption{Curvas de aprendizaje del modelo CNN. \textbf{Panel superior:} Pérdida (loss) vs épocas. La pérdida de entrenamiento (rojo) decrece monótonamente desde ~0.32 hasta ~0.03. La pérdida de validación (azul) sigue un patrón similar, estabilizándose alrededor de 0.04. \textbf{Panel inferior:} Exactitud vs épocas. Ambas curvas convergen rápidamente hacia ~99\%, con la curva de validación mostrando menor varianza después de la época 3.}
    \label{fig:entrenamiento}
\end{figure}

\textbf{Interpretación detallada:}

\begin{enumerate}
    \item \textbf{Fase de aprendizaje rápido (Épocas 1-3):} La pérdida de entrenamiento cae drásticamente de ~0.32 a ~0.08, indicando que el modelo está capturando los patrones principales de los datos. La exactitud salta de ~90\% a ~97\%.
    
    \item \textbf{Fase de refinamiento (Épocas 4-7):} El descenso se ralentiza pero continúa. El modelo está ajustando características más sutiles.
    
    \item \textbf{Fase de convergencia (Épocas 8-10):} Las métricas se estabilizan. Continuar entrenando más allá podría llevar a sobreajuste.
    
    \item \textbf{Diagnóstico de sobreajuste:} La brecha (gap) entre las curvas de entrenamiento y validación permanece pequeña (~0.5\% en exactitud), indicando que el modelo generaliza bien y no hay sobreajuste significativo. El Dropout está cumpliendo su función regularizadora.
\end{enumerate}

\subsubsection{Evolución Detallada por Época}
La Figura \ref{fig:evolucion} presenta una vista granular del progreso del entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{img_evolucion.png}
    \caption{Evolución detallada de métricas por época. Se visualizan las cuatro métricas principales: exactitud y pérdida para entrenamiento (rojo) y validación (azul). La convergencia suave de todas las curvas confirma un entrenamiento estable sin oscilaciones ni divergencias.}
    \label{fig:evolucion}
\end{figure}

% ==================== EVALUACIÓN DEL MODELO ====================
\section{Evaluación del Modelo}

\subsection{Métricas Cuantitativas en el Conjunto de Prueba}

El modelo entrenado se evaluó en las 10,000 imágenes del conjunto de prueba, que nunca fueron vistas durante el entrenamiento.

\begin{table}[H]
\centering
\caption{Resumen de métricas de evaluación}
\begin{tabular}{lcc}
\toprule
\textbf{Métrica} & \textbf{Valor} & \textbf{Interpretación} \\
\midrule
Pérdida (Loss) & 0.0206 & Excelente (objetivo $< 0.1$) \\
Exactitud (Accuracy) & 99.27\% & Estado del arte para esta arquitectura \\
Error & 0.73\% & 73 errores en 10,000 muestras \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Contextualización:}
\begin{itemize}
    \item El récord mundial en MNIST es ~99.8\% (usando modelos ensemble complejos)
    \item Una CNN simple típicamente alcanza 98-99\%
    \item Nuestro resultado de 99.27\% representa un rendimiento excelente para una arquitectura de complejidad moderada
\end{itemize}

\subsection{Análisis de la Matriz de Confusión}

La matriz de confusión proporciona una visión detallada de los patrones de error del clasificador.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img_confusion.png}
    \caption{Matriz de confusión del modelo en el conjunto de prueba. Las filas representan las predicciones del modelo y las columnas las etiquetas verdaderas. La intensidad del color indica la frecuencia (más oscuro = más frecuente). La diagonal muestra clasificaciones correctas; valores fuera de la diagonal son errores.}
    \label{fig:confusion}
\end{figure}

\subsubsection{Interpretación Detallada}

\textbf{Clasificaciones correctas (diagonal):}
\begin{itemize}
    \item Todos los dígitos superan el 97\% de exactitud individual
    \item El dígito ``1'' tiene la mayor exactitud (1131/1135 = 99.6\%)
    \item El dígito ``5'' tiene la menor exactitud relativa (880/892 = 98.7\%)
\end{itemize}

\textbf{Patrones de confusión más frecuentes:}

\begin{table}[H]
\centering
\caption{Principales confusiones del modelo con explicación morfológica}
\begin{tabular}{cccp{5.5cm}}
\toprule
\textbf{Real} & \textbf{Predicho} & \textbf{Casos} & \textbf{Explicación} \\
\midrule
3 & 5 & 9 & Ambos tienen curvas superiores similares \\
9 & 4 & 4 & El lazo cerrado del 9 puede parecer la cabeza del 4 \\
2 & 7 & 4 & Algunas variantes del 2 sin curva inferior \\
5 & 3 & 6 & Inversión del caso 3→5 \\
8 & 5 & 2 & La mitad inferior del 8 puede confundirse \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Observaciones importantes:}
\begin{enumerate}
    \item Los errores son \textbf{simétricos} en muchos casos (3↔5, 4↔9), lo que sugiere ambigüedad genuina en algunas muestras.
    
    \item Los errores están \textbf{concentrados en un pequeño subconjunto} de pares de clases; la mayoría de las combinaciones tienen 0-2 errores.
    
    \item Algunos errores pueden atribuirse a \textbf{mala calidad del etiquetado original} o a muestras genuinamente ambiguas.
\end{enumerate}

\subsection{Análisis por Clase}

\begin{table}[H]
\centering
\caption{Métricas de rendimiento por clase}
\begin{tabular}{ccccc}
\toprule
\textbf{Dígito} & \textbf{Verdaderos} & \textbf{Correctos} & \textbf{Exactitud} & \textbf{Errores típicos} \\
\midrule
0 & 980 & 977 & 99.7\% & →6,8 \\
1 & 1135 & 1131 & 99.6\% & →7,2 \\
2 & 1032 & 1026 & 99.4\% & →7,3 \\
3 & 1010 & 1004 & 99.4\% & →5,2,8 \\
4 & 982 & 976 & 99.4\% & →9,6 \\
5 & 892 & 880 & 98.7\% & →3,6,8 \\
6 & 958 & 951 & 99.3\% & →0,5 \\
7 & 1028 & 1021 & 99.3\% & →2,1,9 \\
8 & 974 & 967 & 99.3\% & →3,5 \\
9 & 1009 & 994 & 98.5\% & →4,3,7 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Análisis de Errores de Clasificación}

La Figura \ref{fig:errores} presenta ejemplos de imágenes que el modelo clasificó incorrectamente.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img_errores.png}
    \caption{Ejemplos de clasificaciones erróneas. Cada imagen muestra la etiqueta real y la predicción del modelo. Nótese que muchos errores involucran muestras genuinamente ambiguas: dígitos mal escritos, incompletos o con características atípicas que podrían confundir incluso a un humano.}
    \label{fig:errores}
\end{figure}

\textbf{Interpretación:} El análisis visual de los errores revela que la mayoría corresponde a casos límite donde la escritura es particularmente irregular o el dígito presenta características atípicas de su clase.

\subsection{Análisis de Confianza del Modelo}

La Figura \ref{fig:confianza} muestra la distribución de probabilidades máximas asignadas por el modelo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{img_confianza.png}
    \caption{Distribución de confianza del modelo. Se muestra la probabilidad máxima asignada a cada predicción, separando clasificaciones correctas (verde) de incorrectas (rojo). La mayoría de predicciones correctas tienen confianza cercana a 1.0, mientras que los errores tienden a tener distribuciones de confianza más bajas, indicando que el modelo ``sabe cuando no sabe''.}
    \label{fig:confianza}
\end{figure}

\textbf{Interpretación:} Este análisis demuestra que el modelo exhibe calibración razonable: las predicciones incorrectas generalmente tienen menor confianza, lo cual es útil para aplicaciones donde se requiere rechazar predicciones inciertas.

% ==================== CONCLUSIONES ====================
\section{Conclusiones}

El presente estudio logró satisfactoriamente todos los objetivos planteados, demostrando la viabilidad y efectividad de implementar modelos de aprendizaje profundo en R para tareas de visión por computadora. A continuación se presentan las conclusiones organizadas por área temática.

\subsection{Sobre el Rendimiento del Modelo}

\begin{enumerate}
    \item \textbf{Exactitud alcanzada:} Con un 99.27\% de exactitud en el conjunto de prueba, el modelo supera el umbral objetivo del 98\% y se posiciona competitivamente respecto a implementaciones similares reportadas en la literatura.
    
    \item \textbf{Generalización:} La pequeña brecha entre las métricas de entrenamiento y validación (~0.5\%) indica una excelente capacidad de generalización, sin evidencia de sobreajuste significativo.
    
    \item \textbf{Eficiencia de parámetros:} Con solo 225,034 parámetros, el modelo alcanza resultados comparables a arquitecturas más complejas, evidenciando un diseño eficiente.
\end{enumerate}

\subsection{Sobre la Arquitectura CNN}

\begin{enumerate}
    \item \textbf{Efectividad de la convolución:} Las capas convolucionales demostraron su capacidad para aprender jerárquicamente: la primera capa detecta bordes y texturas básicas, mientras que la segunda combina estos patrones en formas más complejas características de cada dígito.
    
    \item \textbf{Rol del Dropout:} La regularización mediante Dropout con tasa 0.5 fue efectiva para prevenir el sobreajuste, manteniendo la consistencia entre entrenamiento y validación.
    
    \item \textbf{Profundidad suficiente:} Dos bloques convolucionales resultaron suficientes para el problema MNIST, lo cual es consistente con la relativa simplicidad de las imágenes ($28 \times 28$, escala de grises, dígitos centrados).
\end{enumerate}

\subsection{Sobre los Patrones de Error}

\begin{enumerate}
    \item \textbf{Confusiones predecibles:} Los errores del modelo se concentran en pares de dígitos con similitudes morfológicas genuinas (3-5, 4-9, 2-7), lo cual refleja la ambigüedad inherente a algunas muestras más que limitaciones del modelo.
    
    \item \textbf{Errores mínimos:} Con solo 73 clasificaciones incorrectas de 10,000, el modelo comete un error aproximadamente cada 137 imágenes, un rendimiento que sería aceptable para la mayoría de aplicaciones prácticas.
\end{enumerate}

\subsection{Sobre la Metodología}

\begin{enumerate}
    \item \textbf{Valor del marco IBM:} La Metodología Fundacional de IBM proporcionó una estructura clara que facilitó la organización del trabajo, la documentación y la reproducibilidad del estudio.
    
    \item \textbf{Importancia del preprocesamiento:} Las transformaciones de datos (normalización, reestructuración, codificación) fueron fundamentales para el éxito del entrenamiento. Un preprocesamiento inadecuado habría resultado en convergencia lenta o fallida.
\end{enumerate}

\subsection{Sobre la Implementación en R}

\begin{enumerate}
    \item \textbf{Viabilidad demostrada:} R, a través de la integración con Keras/TensorFlow, es una plataforma completamente viable para proyectos de aprendizaje profundo, con la ventaja adicional de sus capacidades nativas en visualización y análisis estadístico.
    
    \item \textbf{Ecosistema maduro:} Las bibliotecas utilizadas (tidyverse, keras, ggplot2) ofrecen APIs elegantes y bien documentadas que facilitan el desarrollo.
\end{enumerate}

\subsection{Limitaciones y Trabajo Futuro}

\textbf{Limitaciones del estudio:}
\begin{itemize}
    \item No se exploró aumento de datos (data augmentation)
    \item No se realizó optimización sistemática de hiperparámetros
    \item El modelo fue evaluado solo en MNIST, no en datasets más desafiantes
\end{itemize}

\textbf{Direcciones para trabajo futuro:}
\begin{enumerate}
    \item Implementar aumento de datos (rotación, desplazamiento, zoom) para mejorar robustez
    \item Explorar arquitecturas más profundas o residuales (ResNet)
    \item Aplicar técnicas de interpretabilidad (Grad-CAM, SHAP) para visualizar qué aprende el modelo
    \item Evaluar en datasets más complejos (EMNIST, Fashion-MNIST, CIFAR-10)
    \item Investigar técnicas de cuantización para despliegue en dispositivos móviles
\end{enumerate}

% ==================== REFERENCIAS ====================
\section{Referencias Bibliográficas}

\begin{enumerate}
    \item LeCun, Y., Cortes, C., \& Burges, C. J. (1998). The MNIST database of handwritten digits. Disponible en: \textit{http://yann.lecun.com/exdb/mnist/}
    
    \item LeCun, Y., Bottou, L., Bengio, Y., \& Haffner, P. (1998). Gradient-based learning applied to document recognition. \textit{Proceedings of the IEEE}, 86(11), 2278-2324. DOI: 10.1109/5.726791
    
    \item Goodfellow, I., Bengio, Y., \& Courville, A. (2016). \textit{Deep Learning}. MIT Press. ISBN: 978-0262035613
    
    \item Chollet, F. (2017). \textit{Deep Learning with Python}. Manning Publications. ISBN: 978-1617294433
    
    \item He, K., Zhang, X., Ren, S., \& Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. \textit{Proceedings of the IEEE International Conference on Computer Vision}, 1026-1034.
    
    \item Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., \& Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. \textit{Journal of Machine Learning Research}, 15(1), 1929-1958.
    
    \item Kingma, D. P., \& Ba, J. (2014). Adam: A method for stochastic optimization. \textit{arXiv preprint arXiv:1412.6980}.
    
    \item IBM. (2015). Foundational Methodology for Data Science. \textit{IBM Analytics White Paper}.
    
    \item Allaire, J. J., \& Chollet, F. (2023). keras: R Interface to 'Keras'. Disponible en: \textit{https://keras.rstudio.com/}
    
    \item Wickham, H., et al. (2019). Welcome to the tidyverse. \textit{Journal of Open Source Software}, 4(43), 1686. DOI: 10.21105/joss.01686
    
    \item R Core Team (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria.
    
    \item Kaggle. (2023). MNIST Dataset. Disponible en: \textit{https://www.kaggle.com/datasets/hojjatk/mnist-dataset}
\end{enumerate}

% ==================== ANEXO ====================
\section{Anexo}

\subsection{Anexo A: Código Fuente - Funciones de Lectura IDX}

El formato IDX es un formato binario simple pero específico. Las siguientes funciones implementan la lectura correcta en R:

\begin{lstlisting}[caption={Funciones para lectura de archivos en formato IDX}]
# Lectura de imagenes IDX
read_idx_images <- function(path) {
  f <- file(path, "rb")
  on.exit(close(f))
  
  # Leer cabecera (big-endian)
  magic <- readBin(f, integer(), n=1, endian="big")
  num_images <- readBin(f, integer(), n=1, endian="big")
  rows <- readBin(f, integer(), n=1, endian="big")
  cols <- readBin(f, integer(), n=1, endian="big")
  
  # Leer datos de pixeles
  data <- readBin(f, integer(), n=num_images * rows * cols, 
                  size=1, signed=FALSE)
  
  # Reorganizar dimensiones (R es column-major)
  array(data, dim = c(cols, rows, num_images)) %>% 
    aperm(c(3, 2, 1))
}

# Lectura de etiquetas IDX
read_idx_labels <- function(path) {
  f <- file(path, "rb")
  on.exit(close(f))
  
  magic <- readBin(f, integer(), n=1, endian="big")
  num_items <- readBin(f, integer(), n=1, endian="big")
  
  readBin(f, integer(), n=num_items, size=1, signed=FALSE)
}
\end{lstlisting}

\subsection{Anexo B: Código Fuente - Definición del Modelo CNN}

\begin{lstlisting}[caption={Arquitectura completa de la Red Neuronal Convolucional}]
# Definicion del modelo secuencial
model <- keras_model_sequential() %>%
  
  # Primer bloque convolucional
  layer_conv_2d(filters = 32, 
                kernel_size = c(3, 3), 
                activation = 'relu', 
                input_shape = c(28, 28, 1)) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  # Segundo bloque convolucional
  layer_conv_2d(filters = 64, 
                kernel_size = c(3, 3), 
                activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  
  # Cabeza de clasificacion
  layer_flatten() %>%
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 10, activation = 'softmax')

# Compilacion del modelo
model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_adam(),
  metrics = c('accuracy')
)

# Entrenamiento
history <- model %>% fit(
  x_train, y_train,
  epochs = 10,
  batch_size = 128,
  validation_split = 0.1,
  verbose = 2
)
\end{lstlisting}

\subsection{Anexo C: Código Fuente - Visualización de Matriz de Confusión}

\begin{lstlisting}[caption={Generación de matriz de confusión con ggplot2}]
# Obtener predicciones
predictions <- model %>% predict(x_test) %>% k_argmax()
predicted_labels <- as.integer(predictions)

# Crear matriz de confusion
conf_matrix <- table(Predicted = predicted_labels, 
                     Actual = y_test_raw)

# Visualizar con ggplot2
conf_df <- as.data.frame(conf_matrix)
ggplot(conf_df, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = Freq), color = "black") +
  theme_minimal() +
  labs(title = "Matriz de Confusion",
       x = "Etiqueta Real",
       y = "Prediccion")
\end{lstlisting}

\subsection{Anexo D: Glosario de Términos}

\begin{description}
    \item[Batch Size:] Número de muestras procesadas antes de actualizar los pesos del modelo.
    \item[CNN:] Red Neuronal Convolucional, arquitectura especializada para procesamiento de imágenes.
    \item[Dropout:] Técnica de regularización que desactiva aleatoriamente neuronas durante el entrenamiento.
    \item[Época (Epoch):] Una pasada completa por todo el conjunto de entrenamiento.
    \item[Exactitud (Accuracy):] Proporción de predicciones correctas sobre el total.
    \item[Función de Activación:] Función no lineal aplicada a la salida de cada neurona.
    \item[Gradiente:] Derivada de la función de pérdida respecto a los parámetros del modelo.
    \item[One-Hot Encoding:] Representación de variables categóricas como vectores binarios.
    \item[Overfitting:] Cuando el modelo memoriza los datos de entrenamiento sin generalizar.
    \item[Pérdida (Loss):] Medida del error entre predicciones y valores reales.
    \item[Pooling:] Operación de reducción de dimensionalidad espacial.
    \item[ReLU:] Rectified Linear Unit, función de activación $f(x) = max(0, x)$.
    \item[Softmax:] Función que convierte un vector en distribución de probabilidad.
\end{description}

\end{document}
